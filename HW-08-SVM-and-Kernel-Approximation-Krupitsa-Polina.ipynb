{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 04.02.2023\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 20.02.2023\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 26.02.2023\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (1.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всякие импорты\n",
    "import numpy as np\n",
    "import statistics\n",
    "import math\n",
    "np.random.seed(0) \n",
    "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
    "from sklearn.decomposition import PCA  # to apply PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подсчета эвристики\n",
    "\n",
    "def sigma_squared(x):\n",
    "    new_dim = x.shape[1]\n",
    "    rng = np.random.default_rng()\n",
    "    sum = np.zeros(1000000)\n",
    "    for i in range(new_dim):                    # прохожусь по всем столбцам в матрице\n",
    "        first = rng.choice(x[:, i], 1000000)    # генерим миллион рандомных значений из столбца \n",
    "        second = rng.choice(x[:, i], 1000000)   # генерим еще миллион чтобы образовать пары\n",
    "        diff = (first - second) ** 2\n",
    "        sum += diff                             # суммируем столбцы\n",
    "    sigma_2 = statistics.median(sum)\n",
    "    return sigma_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.use_PCA: \n",
    "            self.pca = PCA(n_components = self.new_dim)\n",
    "            self.pca.fit(X)\n",
    "            X = self.pca.transform(X)\n",
    "        sigma_2 = sigma_squared(X)\n",
    "        self.w = np.random.normal(0, (1/math.sqrt(sigma_2)), size = (X.shape[1], self.n_features)) \n",
    "        self.b = np.random.uniform(-math.pi, math.pi, self.n_features)\n",
    "        phi = np.cos(np.dot(X, self.w) + self.b)\n",
    "        if self.classifier == \"logreg\":\n",
    "            self.logreg = LogisticRegression(random_state=0)\n",
    "            self.logreg.fit(phi, y)\n",
    "        else:\n",
    "            self.clf = LinearSVC(random_state=0)\n",
    "            self.clf.fit(phi, y)\n",
    "  \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        phi = np.cos(np.dot(X, self.w) + self.b)\n",
    "        return predict_proba(phi)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        phi = np.cos(np.dot(X, self.w) + self.b)\n",
    "        if self.classifier == 'logreg': \n",
    "            \n",
    "            return self.logreg.predict(phi)\n",
    "        else: \n",
    "    \n",
    "            return self.clf.predict(phi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff = RFFPipeline()\n",
    "rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение на исходных признаках ядровым SVM оказалось более продуктивным: accuracy 0.88 и обучение всего 3.87 минуты. Но в то же время градиентный бустинг тоже показывает себя очень хорошо, по сравнению со случайными признаками. В принципе можно выбирать разные модели в зависимости от того, есть ли какие-то ограничения по времени: дольше всего работает RFF + linear SVM, при этом выдает не самое лучшее качество. Самый быстрый - бустинг, который выдал 0.85 за 0.27 секунды. Но по accuracy выигрывает kernel SVM на исходных данных и бустинг на исходных: по 0.88. Таким образом идея со случайными признаками хоть и работает, но не сильно то и помогает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel SVM на исходных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]моделька обучалась 3.8658482829729715 минут\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8828"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(random_state=0)\n",
    "t1 = time.time()\n",
    "clf.fit(x_train, y_train)\n",
    "t2 = time.time()\n",
    "print('моделька обучалась', (t2 - t1)/60, \"минут\")\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear SVM  на исходных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "моделька обучалась 3.959287710984548 минут\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8019"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(random_state=0)\n",
    "t1 = time.time()\n",
    "clf.fit(x_train, y_train)\n",
    "t2 = time.time()\n",
    "print('моделька обучалась', (t2 - t1)/60, \"минут\")\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + RFF + linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "моделька обучалась 4.901317878564199 минут\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8702"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff = RFFPipeline(classifier='svm')\n",
    "t1 = time.time()\n",
    "rff.fit(x_train.astype(np.float64), y_train)\n",
    "t2 = time.time()\n",
    "print('моделька обучалась', (t2 - t1)/60, \"минут\")\n",
    "y_pred = rff.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFF + linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "моделька обучалась 5.230402612686158 минут\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8581"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff = RFFPipeline(use_PCA=False, classifier='svm')\n",
    "t1 = time.time()\n",
    "rff.fit(x_train.astype(np.float64), y_train)\n",
    "t2 = time.time()\n",
    "print('моделька обучалась', (t2 - t1)/60, \"минут\")\n",
    "y_pred = rff.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + RFF + logreg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "моделька обучалась 0.37270432313283286 минут\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8576"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff = RFFPipeline()\n",
    "t1 = time.time()\n",
    "rff.fit(x_train, y_train)\n",
    "t2 = time.time()\n",
    "print('моделька обучалась', (t2 - t1)/60, \"минут\")\n",
    "y_pred = rff.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFF + logreg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "моделька обучалась 0.6232046127319336 минут\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8631"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff = RFFPipeline(use_PCA=False)\n",
    "t1 = time.time()\n",
    "rff.fit(x_train.astype(np.float64), y_train)\n",
    "t2 = time.time()\n",
    "print('моделька обучалась', (t2 - t1)/60, \"минут\")\n",
    "y_pred = rff.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор параметров для бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01 max_depth: 10 n_estimators 10 accuracy:  0.8495 моделька обучалась 51.2 секунд\n",
      "lr: 0.1 max_depth: 10 n_estimators 10 accuracy:  0.8636 моделька обучалась 50.13 секунд\n",
      "lr: 1 max_depth: 10 n_estimators 10 accuracy:  0.8643 моделька обучалась 49.03 секунд\n",
      "lr: 0.01 max_depth: 10 n_estimators 20 accuracy:  0.8567 моделька обучалась 100.73 секунд\n",
      "lr: 0.1 max_depth: 10 n_estimators 20 accuracy:  0.8701 моделька обучалась 101.09 секунд\n",
      "lr: 1 max_depth: 10 n_estimators 20 accuracy:  0.8736 моделька обучалась 91.88 секунд\n",
      "lr: 0.01 max_depth: 10 n_estimators 50 accuracy:  0.8645 моделька обучалась 248.79 секунд\n",
      "lr: 0.1 max_depth: 10 n_estimators 50 accuracy:  0.8812 моделька обучалась 247.05 секунд\n",
      "lr: 1 max_depth: 10 n_estimators 50 accuracy:  0.8829 моделька обучалась 192.35 секунд\n",
      "lr: 0.01 max_depth: 20 n_estimators 10 accuracy:  0.8522 моделька обучалась 98.94 секунд\n",
      "lr: 0.1 max_depth: 20 n_estimators 10 accuracy:  0.8686 моделька обучалась 97.67 секунд\n",
      "lr: 1 max_depth: 20 n_estimators 10 accuracy:  0.8658 моделька обучалась 76.63 секунд\n",
      "lr: 0.01 max_depth: 20 n_estimators 20 accuracy:  0.8598 моделька обучалась 196.65 секунд\n",
      "lr: 0.1 max_depth: 20 n_estimators 20 accuracy:  0.8741 моделька обучалась 192.53 секунд\n",
      "lr: 1 max_depth: 20 n_estimators 20 accuracy:  0.8726 моделька обучалась 124.34 секунд\n",
      "lr: 0.01 max_depth: 20 n_estimators 50 accuracy:  0.8681 моделька обучалась 486.57 секунд\n",
      "lr: 0.1 max_depth: 20 n_estimators 50 accuracy:  0.8826 моделька обучалась 447.16 секунд\n",
      "lr: 1 max_depth: 20 n_estimators 50 accuracy:  0.8798 моделька обучалась 227.06 секунд\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_6064\\3776640789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1488\u001b[0m             )\n\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1490\u001b[1;33m             self._Booster = train(\n\u001b[0m\u001b[0;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_xgb = []\n",
    "for j in [10, 20, 50]: \n",
    "    for k in [10, 20, 50]:\n",
    "        for i in [0.01, 0.1, 1]:\n",
    "            \n",
    "            bst = XGBClassifier(n_estimators=k, max_depth=j, learning_rate=i)\n",
    "            t1 = time.time()\n",
    "            bst.fit(x_train, y_train)\n",
    "            t2 = time.time()\n",
    "            preds = bst.predict(x_test)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            print(\"lr:\", i, 'max_depth:', j, 'n_estimators', k, 'accuracy: ', acc, 'моделька обучалась', round((t2 - t1), 2), \"секунд\")\n",
    "            acc_xgb.append(acc)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если честно мне стало лень ждать до конца но качество 0.8829 и так более чем достаточно c параметрами lr: 1 max_depth: 10 n_estimators: 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 10 n_estimators 10 accuracy:  0.8601 моделька обучалась 15.79 секунд\n",
      "max_depth: 10 n_estimators 20 accuracy:  0.8368 моделька обучалась 19.56 секунд\n",
      "max_depth: 10 n_estimators 50 accuracy:  0.8419 моделька обучалась 20.79 секунд\n",
      "max_depth: 20 n_estimators 10 accuracy:  0.8398 моделька обучалась 28.43 секунд\n",
      "max_depth: 20 n_estimators 20 accuracy:  0.8482 моделька обучалась 32.22 секунд\n",
      "max_depth: 20 n_estimators 50 accuracy:  0.848 моделька обучалась 32.73 секунд\n",
      "max_depth: 50 n_estimators 10 accuracy:  0.8463 моделька обучалась 58.08 секунд\n",
      "max_depth: 50 n_estimators 20 accuracy:  0.8576 моделька обучалась 60.0 секунд\n",
      "max_depth: 50 n_estimators 50 accuracy:  0.8559 моделька обучалась 60.55 секунд\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "pca.fit(x_train)\n",
    "x_train_pca = pca.transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "acc_xgb = []\n",
    "for j in [10, 20, 50]: \n",
    "    for k in [10, 20, 50]:\n",
    "        bst = XGBClassifier(n_estimators= j, max_depth=k, learning_rate=1)\n",
    "        t1 = time.time()\n",
    "        bst.fit(x_train_pca, y_train)\n",
    "        t2 = time.time()\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        preds = bst.predict(x_test_pca)\n",
    "        print('max_depth:', j, 'n_estimators', k, 'accuracy: ', acc, 'моделька обучалась', round((t2 - t1), 2), \"секунд\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 n_estimators 1 accuracy:  0.8549 моделька обучалась 0.27 секунд\n",
      "max_depth: 1 n_estimators 3 accuracy:  0.5155 моделька обучалась 0.61 секунд\n",
      "max_depth: 1 n_estimators 5 accuracy:  0.7173 моделька обучалась 0.95 секунд\n",
      "max_depth: 1 n_estimators 10 accuracy:  0.7645 моделька обучалась 1.99 секунд\n",
      "max_depth: 1 n_estimators 20 accuracy:  0.8077 моделька обучалась 2.73 секунд\n",
      "max_depth: 1 n_estimators 50 accuracy:  0.8068 моделька обучалась 2.92 секунд\n",
      "max_depth: 3 n_estimators 1 accuracy:  0.8065 моделька обучалась 0.58 секунд\n",
      "max_depth: 3 n_estimators 3 accuracy:  0.6473 моделька обучалась 1.59 секунд\n",
      "max_depth: 3 n_estimators 5 accuracy:  0.7524 моделька обучалась 2.64 секунд\n",
      "max_depth: 3 n_estimators 10 accuracy:  0.792 моделька обучалась 5.42 секунд\n",
      "max_depth: 3 n_estimators 20 accuracy:  0.8185 моделька обучалась 7.54 секунд\n",
      "max_depth: 3 n_estimators 50 accuracy:  0.8198 моделька обучалась 8.31 секунд\n",
      "max_depth: 5 n_estimators 1 accuracy:  0.8193 моделька обучалась 0.92 секунд\n",
      "max_depth: 5 n_estimators 3 accuracy:  0.6793 моделька обучалась 2.63 секунд\n",
      "max_depth: 5 n_estimators 5 accuracy:  0.7765 моделька обучалась 4.35 секунд\n",
      "max_depth: 5 n_estimators 10 accuracy:  0.8086 моделька обучалась 8.52 секунд\n",
      "max_depth: 5 n_estimators 20 accuracy:  0.8285 моделька обучалась 11.55 секунд\n",
      "max_depth: 5 n_estimators 50 accuracy:  0.8294 моделька обучалась 12.32 секунд\n",
      "max_depth: 10 n_estimators 1 accuracy:  0.8283 моделька обучалась 1.67 секунд\n",
      "max_depth: 10 n_estimators 3 accuracy:  0.7246 моделька обучалась 5.18 секунд\n",
      "max_depth: 10 n_estimators 5 accuracy:  0.8051 моделька обучалась 8.64 секунд\n",
      "max_depth: 10 n_estimators 10 accuracy:  0.826 моделька обучалась 15.77 секунд\n",
      "max_depth: 10 n_estimators 20 accuracy:  0.8358 моделька обучалась 19.71 секунд\n",
      "max_depth: 10 n_estimators 50 accuracy:  0.8427 моделька обучалась 20.45 секунд\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "pca.fit(x_train)\n",
    "x_train_pca = pca.transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "acc_xgb = []\n",
    "for j in [1, 3, 5, 10]: \n",
    "    for k in [1, 3, 5, 10, 20, 50]:\n",
    "        bst = XGBClassifier(n_estimators= j, max_depth=k, learning_rate=1)\n",
    "        t1 = time.time()\n",
    "        bst.fit(x_train_pca, y_train)\n",
    "        t2 = time.time()\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        preds = bst.predict(x_test_pca)\n",
    "        print('max_depth:', j, 'n_estimators', k, 'accuracy: ', acc, 'моделька обучалась', round((t2 - t1), 2), \"секунд\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С PCA самый лучший вариант получился lr: 1, max_depth: 10 n_estimators 10 accuracy:  0.8601 моделька обучалась 15.79 секунд, но еще очень забавно, что тоже неплохой результат выдало lr: 1, max_depth: 1 n_estimators 1 accuracy:  0.8549, причем всего за 0.27 секунды)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "source": [
    "1. В случае с линейным SVM  качество с PCA выросло: без PCA 0.8581, с PCA 0.8702. Время обучения сократилось с 5.23 до 4.9 минут. PCA помог! Однако для логистической регрессии PCA помог только со временем обучения: снизил с 0.62 до  0.37 минут. Но при этом качество модели упало: без PCA 0.8631, с PCA 0.8576."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8624\n"
     ]
    }
   ],
   "source": [
    "acc_logreg = []\n",
    "n_features_i = [10, 50, 100, 150, 250, 500, 750, 1000, 1250, 1500, 1750, 2000]\n",
    "for i in n_features_i: \n",
    "    rff = RFFPipeline(n_features = i)\n",
    "    rff.fit(x_train, y_train)\n",
    "    y_pred = rff.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(acc)\n",
    "    acc_logreg.append(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5812\n",
      "0.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795\n"
     ]
    }
   ],
   "source": [
    "acc_svm = []\n",
    "for i in n_features_i: \n",
    "    rff = RFFPipeline(n_features = i, classifier='svm' )\n",
    "    rff.fit(x_train, y_train)\n",
    "    y_pred = rff.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(acc)\n",
    "    acc_svm.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(n_features_i, acc_logreg, label = 'logreg')\n",
    "plt.plot(n_features_i, acc_svm, label = 'svm')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('n_features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Качество повышается с увеличением n_features, но выходит на плато примерно после n_features = 1000, svm выдает accuracy выше, чем логрег, но их поведение при увеличении количества features одинаковое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
